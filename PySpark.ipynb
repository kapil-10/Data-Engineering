{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3e15e4",
   "metadata": {},
   "source": [
    "# Pyspark by Kapil Verma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed73286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income ($)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work Experience</th>\n",
       "      <th>Family Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15000</td>\n",
       "      <td>39</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>35000</td>\n",
       "      <td>81</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>86000</td>\n",
       "      <td>6</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>59000</td>\n",
       "      <td>77</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>38000</td>\n",
       "      <td>40</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>Female</td>\n",
       "      <td>71</td>\n",
       "      <td>184387</td>\n",
       "      <td>40</td>\n",
       "      <td>Artist</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>Female</td>\n",
       "      <td>91</td>\n",
       "      <td>73158</td>\n",
       "      <td>32</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>Male</td>\n",
       "      <td>87</td>\n",
       "      <td>90961</td>\n",
       "      <td>14</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Male</td>\n",
       "      <td>77</td>\n",
       "      <td>182109</td>\n",
       "      <td>4</td>\n",
       "      <td>Executive</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>Male</td>\n",
       "      <td>90</td>\n",
       "      <td>110610</td>\n",
       "      <td>52</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerID  Gender  Age  Annual Income ($)  Spending Score (1-100)  \\\n",
       "0              1    Male   19              15000                      39   \n",
       "1              2    Male   21              35000                      81   \n",
       "2              3  Female   20              86000                       6   \n",
       "3              4  Female   23              59000                      77   \n",
       "4              5  Female   31              38000                      40   \n",
       "...          ...     ...  ...                ...                     ...   \n",
       "1995        1996  Female   71             184387                      40   \n",
       "1996        1997  Female   91              73158                      32   \n",
       "1997        1998    Male   87              90961                      14   \n",
       "1998        1999    Male   77             182109                       4   \n",
       "1999        2000    Male   90             110610                      52   \n",
       "\n",
       "         Profession  Work Experience  Family Size  \n",
       "0        Healthcare                1            4  \n",
       "1          Engineer                3            3  \n",
       "2          Engineer                1            1  \n",
       "3            Lawyer                0            2  \n",
       "4     Entertainment                2            6  \n",
       "...             ...              ...          ...  \n",
       "1995         Artist                8            7  \n",
       "1996         Doctor                7            7  \n",
       "1997     Healthcare                9            2  \n",
       "1998      Executive                7            2  \n",
       "1999  Entertainment                5            2  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "file=r'C:\\Users\\Kapil\\Downloads\\Customers.csv'\n",
    "pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9aa8a",
   "metadata": {},
   "source": [
    "`SparkSession` is the entry point to Spark functionality. It allows you to interact with Spark and utilize its features to process and analyze data. The `SparkSession.builder` is used to create a `SparkSession` instance. Here's what each part of the code you provided does:\n",
    "\n",
    "1. `SparkSession.builder`: This creates a builder that is used to configure the `SparkSession` before actually creating it.\n",
    "\n",
    "2. `appName('Practise')`: This sets the name of your Spark application to 'Practise'. This name will be visible in the Spark UI, which is helpful for monitoring and debugging.\n",
    "\n",
    "3. `getOrCreate()`: This method tries to find an existing `SparkSession` instance or, if it doesn't exist, creates a new one. This is useful because Spark is designed to have only one active `SparkSession` per JVM.\n",
    "\n",
    "So, by using `SparkSession.builder.appName('Practise').getOrCreate()`, you ensure that you have a `SparkSession` instance named 'Practise' available for use in your Spark application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d828b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1eacb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.105.69:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x20f8bfe9250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d983fb",
   "metadata": {},
   "source": [
    "\n",
    "In PySpark, the inferSchema option is used to automatically infer the schema of the DataFrame from the data. When inferSchema is set to True, PySpark will automatically examine a sample of the data to determine the data types for each column.\n",
    "\n",
    "Setting inferSchema=True is useful when you want PySpark to automatically determine the data types of each column based on the actual data values. This can save you from manually specifying the schema, especially when working with large datasets or when the schema is not known in advance.\n",
    "\n",
    "Here's what happens when you use inferSchema=True:\n",
    "\n",
    "PySpark reads a sample of the data to determine the data types.\n",
    "It infers the schema based on the sampled data.\n",
    "The inferred schema is used to parse the entire dataset.\n",
    "This can be beneficial because it can handle various data types and formats without requiring explicit schema definition. However, it's important to note that inferring the schema can add some overhead, especially for large datasets or datasets with a wide range of data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4ffa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv(file,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce307f",
   "metadata": {},
   "source": [
    "# To check the datatype of the coloumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b6b10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Annual Income ($): integer (nullable = true)\n",
      " |-- Spending Score (1-100): integer (nullable = true)\n",
      " |-- Profession: string (nullable = true)\n",
      " |-- Work Experience: integer (nullable = true)\n",
      " |-- Family Size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3a7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|CustomerID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|         1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|         2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|         3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|         4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|         5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|         6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|         7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|         8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|         9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|        10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|        11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|        12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|        13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|        14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|        15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|        16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|        17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|        18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|        19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|        20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv(file,header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf88bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Annual Income ($): integer (nullable = true)\n",
      " |-- Spending Score (1-100): integer (nullable = true)\n",
      " |-- Profession: string (nullable = true)\n",
      " |-- Work Experience: integer (nullable = true)\n",
      " |-- Family Size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e473c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667da0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CustomerID=1, Gender='Male', Age=19, Annual Income ($)=15000, Spending Score (1-100)=39, Profession='Healthcare', Work Experience=1, Family Size=4),\n",
       " Row(CustomerID=2, Gender='Male', Age=21, Annual Income ($)=35000, Spending Score (1-100)=81, Profession='Engineer', Work Experience=3, Family Size=3),\n",
       " Row(CustomerID=3, Gender='Female', Age=20, Annual Income ($)=86000, Spending Score (1-100)=6, Profession='Engineer', Work Experience=1, Family Size=1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93b3e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|CustomerID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|         1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|         2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|         3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|         4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|         5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|         6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|         7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|         8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|         9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|        10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|        11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|        12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|        13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|        14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|        15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|        16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|        17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|        18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|        19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|        20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a1985c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CustomerID',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Annual Income ($)',\n",
       " 'Spending Score (1-100)',\n",
       " 'Profession',\n",
       " 'Work Experience',\n",
       " 'Family Size']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fad1394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CustomerID: int, Age: int, Profession: string, Work Experience: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark[['CustomerID','Age','Profession', 'Work Experience']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "765e5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CustomerID: int, Age: int, Profession: string, Work Experience: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('CustomerID','Age','Profession', 'Work Experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e469b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+-------------+---------------+\n",
      "|CustomerID|Age|   Profession|Work Experience|\n",
      "+----------+---+-------------+---------------+\n",
      "|         1| 19|   Healthcare|              1|\n",
      "|         2| 21|     Engineer|              3|\n",
      "|         3| 20|     Engineer|              1|\n",
      "|         4| 23|       Lawyer|              0|\n",
      "|         5| 31|Entertainment|              2|\n",
      "|         6| 22|       Artist|              0|\n",
      "|         7| 35|   Healthcare|              1|\n",
      "|         8| 23|   Healthcare|              1|\n",
      "|         9| 64|     Engineer|              0|\n",
      "|        10| 30|       Artist|              1|\n",
      "|        11| 67|     Engineer|              1|\n",
      "|        12| 35|   Healthcare|              4|\n",
      "|        13| 58|    Executive|              0|\n",
      "|        14| 24|       Lawyer|              1|\n",
      "|        15| 37|       Doctor|              0|\n",
      "|        16| 22|   Healthcare|              1|\n",
      "|        17| 35|    Homemaker|              9|\n",
      "|        18| 20|   Healthcare|              1|\n",
      "|        19| 52|Entertainment|              1|\n",
      "|        20| 35|       Artist|              0|\n",
      "+----------+---+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('CustomerID','Age','Profession', 'Work Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f15e558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CustomerID', 'int'),\n",
       " ('Gender', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Annual Income ($)', 'int'),\n",
       " ('Spending Score (1-100)', 'int'),\n",
       " ('Profession', 'string'),\n",
       " ('Work Experience', 'int'),\n",
       " ('Family Size', 'int')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea36c64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, CustomerID: string, Gender: string, Age: string, Annual Income ($): string, Spending Score (1-100): string, Profession: string, Work Experience: string, Family Size: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c6d4ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------+------------------+-----------------+----------------------+----------+------------------+------------------+\n",
      "|summary|       CustomerID|Gender|               Age|Annual Income ($)|Spending Score (1-100)|Profession|   Work Experience|       Family Size|\n",
      "+-------+-----------------+------+------------------+-----------------+----------------------+----------+------------------+------------------+\n",
      "|  count|             2000|  2000|              2000|             2000|                  2000|      1965|              2000|              2000|\n",
      "|   mean|           1000.5|  NULL|             48.96|      110731.8215|               50.9625|      NULL|            4.1025|            3.7685|\n",
      "| stddev|577.4945887192364|  NULL|28.429747189565916|45739.53668828386|     27.93466066346952|      NULL|3.9222041753070958|1.9707485062375214|\n",
      "|    min|                1|Female|                 0|                0|                     0|    Artist|                 0|                 1|\n",
      "|    max|             2000|  Male|                99|           189974|                   100| Marketing|                17|                 9|\n",
      "+-------+-----------------+------+------------------+-----------------+----------------------+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc46b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Columns in data frame\n",
    "df_pyspark=df_pyspark.withColumn('Annual Income After 2 year',df_pyspark['Annual Income ($)']*2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc2e1f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+--------------------------+\n",
      "|CustomerID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|Annual Income After 2 year|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+--------------------------+\n",
      "|         1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|                   31500.0|\n",
      "|         2|  Male| 21|            35000|                    81|     Engineer|              3|          3|                   73500.0|\n",
      "|         3|Female| 20|            86000|                     6|     Engineer|              1|          1|                  180600.0|\n",
      "|         4|Female| 23|            59000|                    77|       Lawyer|              0|          2|                  123900.0|\n",
      "|         5|Female| 31|            38000|                    40|Entertainment|              2|          6|                   79800.0|\n",
      "|         6|Female| 22|            58000|                    76|       Artist|              0|          2|                  121800.0|\n",
      "|         7|Female| 35|            31000|                     6|   Healthcare|              1|          3|                   65100.0|\n",
      "|         8|Female| 23|            84000|                    94|   Healthcare|              1|          3|                  176400.0|\n",
      "|         9|  Male| 64|            97000|                     3|     Engineer|              0|          3|                  203700.0|\n",
      "|        10|Female| 30|            98000|                    72|       Artist|              1|          4|                  205800.0|\n",
      "|        11|  Male| 67|             7000|                    14|     Engineer|              1|          3|                   14700.0|\n",
      "|        12|Female| 35|            93000|                    99|   Healthcare|              4|          4|                  195300.0|\n",
      "|        13|Female| 58|            80000|                    15|    Executive|              0|          5|                  168000.0|\n",
      "|        14|Female| 24|            91000|                    77|       Lawyer|              1|          1|                  191100.0|\n",
      "|        15|  Male| 37|            19000|                    13|       Doctor|              0|          1|                   39900.0|\n",
      "|        16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|                  107100.0|\n",
      "|        17|Female| 35|            29000|                    35|    Homemaker|              9|          5|                   60900.0|\n",
      "|        18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|                  186900.0|\n",
      "|        19|  Male| 52|            20000|                    29|Entertainment|              1|          4|                   42000.0|\n",
      "|        20|Female| 35|            62000|                    98|       Artist|              0|          1|                  130200.0|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "108e0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop the columns\n",
    "df_pyspark=df_pyspark.drop('Annual Income After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767d8347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|CustomerID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|         1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|         2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|         3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|         4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|         5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "+----------+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbe6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename the columns\n",
    "df_pyspark=df_pyspark.withColumnRenamed('CustomerID','C_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de70abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40f2d33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[C_ID: int, Gender: string, Age: int, Annual Income ($): int, Spending Score (1-100): int, Profession: string, Work Experience: int, Family Size: int]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36ce38f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0162fef2",
   "metadata": {},
   "source": [
    "\n",
    "In PySpark, na.drop() is a method used to remove rows containing missing or null values from a DataFrame. The na attribute is a property of DataFrame in PySpark which provides methods for working with missing data.\n",
    "\n",
    "Here's an explanation of df_pyspark.na.drop():\n",
    "\n",
    "DataFrame: df_pyspark represents a DataFrame in PySpark. DataFrames are the primary abstraction in Spark SQL. They represent a distributed collection of data organized into named columns, akin to tables in a relational database, or data frames in R or pandas.\n",
    "\n",
    "na: This is an attribute of the DataFrame df_pyspark which provides methods for working with missing data. na stands for \"missing data\".\n",
    "\n",
    "drop(): drop() is a method provided by the na attribute. It is used to remove rows from the DataFrame that contain any null or NaN values. This method has parameters to control how the dropping operation should be performed.\n",
    "\n",
    "By default, if any null or NaN values are found in any row, the entire row is dropped.\n",
    "\n",
    "You can specify additional parameters such as how and thresh to control the behavior of dropping rows.\n",
    "\n",
    "how: It determines whether to drop the row if any null or NaN value is present (\"any\", default) or only if all values are null or NaN (\"all\").\n",
    "\n",
    "thresh: It specifies the minimum number of non-null values required for a row to be retained. If a row has less than this number of non-null values, it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d96772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec9f99",
   "metadata": {},
   "source": [
    "the `na.drop()` function is used to drop rows containing missing values (nulls or NaNs) from a DataFrame. When you call `na.drop(how=\"any\", subset=['Age'])`, you're indicating that you want to drop rows where there are missing values specifically in the 'Age' column.\n",
    "\n",
    "Here's a breakdown of what's happening:\n",
    "\n",
    "- `df_pyspark`: This is your DataFrame in PySpark.\n",
    "- `.na`: This refers to the DataFrameNaFunctions class, which contains functions for working with missing data.\n",
    "- `.drop(how=\"any\", subset=['Age'])`: This is the method used to drop rows containing missing values. The `how=\"any\"` parameter specifies that if any missing values are found in the specified subset of columns, the entire row should be dropped. The `subset=['Age']` parameter specifies that the operation should only consider the 'Age' column when determining which rows to drop.\n",
    "- `.show()`: This command displays the DataFrame after the rows with missing values in the specified subset have been dropped.\n",
    "\n",
    "So, after executing `df_pyspark.na.drop(how=\"any\", subset=['Age']).show()`, any rows in the DataFrame `df_pyspark` where there are missing values in the 'Age' column will be dropped, and the resulting DataFrame will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b6199c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05e356eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1715b",
   "metadata": {},
   "source": [
    "In PySpark, the na.fill() function is used to fill missing values (nulls or NaNs) in a DataFrame with specified values. When you call na.fill('Missing Values'), you're indicating that you want to fill all missing values in the entire DataFrame with the string 'Missing Values'.\n",
    "\n",
    "Here's a breakdown of what's happening:\n",
    "\n",
    "df_pyspark: This is your DataFrame in PySpark.\n",
    ".na: This refers to the DataFrameNaFunctions class, which contains functions for working with missing data.\n",
    ".fill('Missing Values'): This is the method used to fill missing values in the DataFrame. By passing the string 'Missing Values' as an argument, you're instructing PySpark to replace any missing values in the DataFrame with this specified string.\n",
    ".show(): This command displays the DataFrame after the missing values have been filled.\n",
    "So, after executing df_pyspark.na.fill('Missing Values').show(), any missing values in the DataFrame df_pyspark will be replaced by the string 'Missing Values', and the resulting DataFrame will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f4d1b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filling the missing value\n",
    "df_pyspark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a02650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing Values',['Gender','Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abdc74",
   "metadata": {},
   "source": [
    "The Imputer class from pyspark.ml.feature is used for imputing missing values in a DataFrame. It's particularly useful when you want to replace missing values with some statistical measure (such as mean, median, or mode) of the column containing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04a8ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed8cef",
   "metadata": {},
   "source": [
    "Imputer: This is the class from the pyspark.ml.feature module used for imputing missing values.\n",
    "\n",
    "inputCols: This parameter specifies the columns in your DataFrame that you want to impute missing values for. In this case, it's 'age', 'Experience', and 'Salary'.\n",
    "\n",
    "outputCols: This parameter specifies the names of the output columns after imputation. Here, it's generating new column names with \"_imputed\" appended to the original column names using a list comprehension.\n",
    "\n",
    ".setStrategy(\"median\"): This method sets the strategy for imputation. In this case, you've chosen the strategy to be \"median\", which means the missing values will be replaced with the median value of each respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82123b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "inputCols=['Age','Work Experience','Annual Income ($)','Spending Score (1-100)'],\n",
    "outputCols=['{}_imputed'.format(c) for c in ['Age','Work Experience','Annual Income ($)','Spending Score (1-100)']]\n",
    ").setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef3d1845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daf589d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+-----------+-----------------------+-------------------------+------------------------------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|Age_imputed|Work Experience_imputed|Annual Income ($)_imputed|Spending Score (1-100)_imputed|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+-----------+-----------------------+-------------------------+------------------------------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|         19|                      1|                    15000|                            39|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|         21|                      3|                    35000|                            81|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|         20|                      1|                    86000|                             6|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|         23|                      0|                    59000|                            77|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|         31|                      2|                    38000|                            40|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+-----------+-----------------------+-------------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f17ded2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd3e51",
   "metadata": {},
   "source": [
    "# Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "faf34bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|  34|  Male| 18|            62000|                    92|    Homemaker|              9|          7|\n",
      "|  66|  Male| 18|             9000|                    59|Entertainment|              0|          2|\n",
      "|  92|  Male| 18|            36000|                    41|       Artist|              1|          4|\n",
      "| 115|Female| 18|            97000|                    48|    Executive|              0|          3|\n",
      "| 203|Female| 16|            60000|                     0|     Engineer|              6|          8|\n",
      "| 211|Female|  1|            57000|                    93|     Engineer|              1|          2|\n",
      "| 212|Female|  0|            22000|                    92|       Artist|              2|          1|\n",
      "| 229|  Male|  0|            33000|                    64|    Marketing|              1|          1|\n",
      "| 230|  Male| 15|            94000|                    30|   Healthcare|              7|          2|\n",
      "| 231|Female|  6|            93000|                    53|       Lawyer|              8|          2|\n",
      "| 235|Female|  4|            84000|                    54|       Artist|              9|          1|\n",
      "| 240|Female| 14|            50000|                    11|       Artist|              1|          2|\n",
      "| 257|  Male| 12|            38000|                    18|    Executive|             10|          1|\n",
      "| 266|  Male|  7|            82000|                    39|Entertainment|              2|          2|\n",
      "| 272|Female|  1|            12000|                    82|       Doctor|              0|          3|\n",
      "| 274|Female| 18|           143000|                    99|       Artist|              0|          2|\n",
      "| 277|  Male| 16|             9000|                    88|    Executive|              7|          4|\n",
      "| 291|  Male|  9|            27000|                    62|Entertainment|              7|          1|\n",
      "| 292|Female| 10|            68000|                    80|       Doctor|              6|          3|\n",
      "| 293|  Male| 11|            38000|                    66|       Artist|              8|          8|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Age of the people less than or equal to 18\n",
    "df_pyspark.filter(\"Age<=18\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "140acfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|Age|   profession|\n",
      "+---+-------------+\n",
      "| 18|    Homemaker|\n",
      "| 18|Entertainment|\n",
      "| 18|       Artist|\n",
      "| 18|    Executive|\n",
      "| 16|     Engineer|\n",
      "|  1|     Engineer|\n",
      "|  0|       Artist|\n",
      "|  0|    Marketing|\n",
      "| 15|   Healthcare|\n",
      "|  6|       Lawyer|\n",
      "|  4|       Artist|\n",
      "| 14|       Artist|\n",
      "| 12|    Executive|\n",
      "|  7|Entertainment|\n",
      "|  1|       Doctor|\n",
      "| 18|       Artist|\n",
      "| 16|    Executive|\n",
      "|  9|Entertainment|\n",
      "| 10|       Doctor|\n",
      "| 11|       Artist|\n",
      "+---+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Age<=18\").select(['Age','profession']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c150a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['Age']>=18).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "798a5f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  32|Female| 21|            34000|                    73|       Doctor|              1|          2|\n",
      "|  34|  Male| 18|            62000|                    92|    Homemaker|              9|          7|\n",
      "|  36|Female| 21|            95000|                    81|   Healthcare|              3|          4|\n",
      "|  40|Female| 20|            69000|                    75|       Artist|              8|          2|\n",
      "|  62|  Male| 19|            50000|                    55|       Artist|              9|          2|\n",
      "|  66|  Male| 18|             9000|                    59|Entertainment|              0|          2|\n",
      "|  69|  Male| 19|            81000|                    59|       Artist|              0|          4|\n",
      "|  85|Female| 21|            24000|                    57|    Marketing|              1|          3|\n",
      "|  92|  Male| 18|            36000|                    41|       Artist|              1|          4|\n",
      "| 100|  Male| 20|            80000|                    49|     Engineer|              3|          3|\n",
      "| 106|Female| 21|            82000|                    42|       Doctor|              1|          2|\n",
      "| 112|Female| 19|            25000|                    54|       Artist|              0|          1|\n",
      "| 114|  Male| 19|             2000|                    46|       Artist|              1|          1|\n",
      "| 115|Female| 18|            97000|                    48|    Executive|              0|          3|\n",
      "| 116|Female| 19|            51000|                    50|    Executive|              8|          4|\n",
      "| 135|  Male| 20|            89000|                     5|     Engineer|              1|          2|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter( (df_pyspark['Age']<=21) & (df_pyspark['Age']>=18) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5bf69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# not operation\n",
    "df_pyspark.filter(~(df_pyspark['Age']<=18)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6c62c",
   "metadata": {},
   "source": [
    "# GroupBy And Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf8cc130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+----------------------+---------------------------+--------------------+----------------+\n",
      "|Gender|sum(C_ID)|sum(Age)|sum(Annual Income ($))|sum(Spending Score (1-100))|sum(Work Experience)|sum(Family Size)|\n",
      "+------+---------+--------+----------------------+---------------------------+--------------------+----------------+\n",
      "|Female|  1184029|   57904|             131116706|                      60456|                4786|            4469|\n",
      "|  Male|   816971|   40016|              90346937|                      41469|                3419|            3068|\n",
      "+------+---------+--------+----------------------+---------------------------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby('Gender').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c2225244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+----------------------+---------------------------+--------------------+------------------+\n",
      "|Gender|         avg(C_ID)|          avg(Age)|avg(Annual Income ($))|avg(Spending Score (1-100))|avg(Work Experience)|  avg(Family Size)|\n",
      "+------+------------------+------------------+----------------------+---------------------------+--------------------+------------------+\n",
      "|Female| 998.3381112984823|48.822934232715006|     110553.7150084317|         50.974704890387855|   4.035413153456998|3.7681281618887015|\n",
      "|  Male|1003.6498771498772| 49.15970515970516|     110991.3230958231|          50.94471744471745|     4.2002457002457| 3.769041769041769|\n",
      "+------+------------------+------------------+----------------------+---------------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Gender').avg().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5442a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+------------------+------------------+----------------------+---------------------------+--------------------+------------------+\n",
      "|Work Experience|Gender|         avg(C_ID)|          avg(Age)|avg(Annual Income ($))|avg(Spending Score (1-100))|avg(Work Experience)|  avg(Family Size)|\n",
      "+---------------+------+------------------+------------------+----------------------+---------------------------+--------------------+------------------+\n",
      "|             14|  Male|           593.125|            42.375|             135746.75|                     37.375|                14.0|             3.375|\n",
      "|              7|Female|1216.2054794520548|51.465753424657535|    110778.82191780822|         49.821917808219176|                 7.0|               4.0|\n",
      "|             12|  Male| 659.8333333333334|              61.5|              108705.5|         34.833333333333336|                12.0| 4.166666666666667|\n",
      "|              4|Female|1080.6486486486488| 51.24324324324324|    113056.25675675676|           53.5945945945946|                 4.0| 3.864864864864865|\n",
      "|              9|  Male| 1162.274193548387| 51.11290322580645|    114133.48387096774|          50.91935483870968|                 9.0| 3.838709677419355|\n",
      "|              6|  Male| 1039.734693877551| 48.08163265306123|    116781.85714285714|          58.46938775510204|                 6.0| 3.816326530612245|\n",
      "|             15|Female|           480.875|            43.375|             113727.25|                     57.875|                15.0|             2.875|\n",
      "|             10|  Male|1242.1944444444443| 57.55555555555556|    112181.38888888889|                      49.25|                10.0|3.7222222222222223|\n",
      "|              5|Female| 1088.057142857143| 49.07142857142857|    104118.91428571429|                       48.4|                 5.0| 3.757142857142857|\n",
      "|              3|Female|             789.8|44.833333333333336|    115487.36666666667|                       62.6|                 3.0|               3.7|\n",
      "|             15|  Male| 495.8333333333333|54.333333333333336|    130754.16666666667|         50.166666666666664|                15.0|3.6666666666666665|\n",
      "|              4|  Male|1198.3617021276596| 54.95744680851064|    115242.97872340426|         45.234042553191486|                 4.0|3.7872340425531914|\n",
      "|             13|Female|             564.5|            37.875|             108243.25|                       34.0|                13.0|               3.5|\n",
      "|             16|  Male|             504.5|              29.5|               90231.5|                       60.5|                16.0|               2.5|\n",
      "|             10|Female|1389.0416666666667|            53.125|    118228.54166666667|                      57.25|                10.0|3.7708333333333335|\n",
      "|              1|Female| 879.9590443686006| 48.13993174061434|    108130.73037542662|         50.034129692832764|                 1.0|3.6552901023890785|\n",
      "|             16|Female| 459.3333333333333|44.666666666666664|     95501.66666666667|                       15.0|                16.0|               2.0|\n",
      "|              2|  Male| 720.4166666666666|41.291666666666664|     97452.04166666667|                       60.0|                 2.0|3.3333333333333335|\n",
      "|             13|  Male|           512.625|              42.5|            143906.625|                     51.375|                13.0|             2.875|\n",
      "|              7|  Male| 1148.811320754717|48.698113207547166|    112091.11320754717|          50.35849056603774|                 7.0| 4.056603773584905|\n",
      "+---------------+------+------------------+------------------+----------------------+---------------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Groupby Work Experience  which gives maximum salary\n",
    "df_pyspark.groupBy('Work Experience','Gender').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09e9a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|sum(Family Size)|\n",
      "+----------------+\n",
      "|            7537|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Family Size':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6aa407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=[\"Age\",\"Work Experience\"],outputCol=\"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "08fe4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9ca2321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+--------------------+\n",
      "|C_ID|Gender|Age|Annual Income ($)|Spending Score (1-100)|   Profession|Work Experience|Family Size|Independent Features|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+--------------------+\n",
      "|   1|  Male| 19|            15000|                    39|   Healthcare|              1|          4|          [19.0,1.0]|\n",
      "|   2|  Male| 21|            35000|                    81|     Engineer|              3|          3|          [21.0,3.0]|\n",
      "|   3|Female| 20|            86000|                     6|     Engineer|              1|          1|          [20.0,1.0]|\n",
      "|   4|Female| 23|            59000|                    77|       Lawyer|              0|          2|          [23.0,0.0]|\n",
      "|   5|Female| 31|            38000|                    40|Entertainment|              2|          6|          [31.0,2.0]|\n",
      "|   6|Female| 22|            58000|                    76|       Artist|              0|          2|          [22.0,0.0]|\n",
      "|   7|Female| 35|            31000|                     6|   Healthcare|              1|          3|          [35.0,1.0]|\n",
      "|   8|Female| 23|            84000|                    94|   Healthcare|              1|          3|          [23.0,1.0]|\n",
      "|   9|  Male| 64|            97000|                     3|     Engineer|              0|          3|          [64.0,0.0]|\n",
      "|  10|Female| 30|            98000|                    72|       Artist|              1|          4|          [30.0,1.0]|\n",
      "|  11|  Male| 67|             7000|                    14|     Engineer|              1|          3|          [67.0,1.0]|\n",
      "|  12|Female| 35|            93000|                    99|   Healthcare|              4|          4|          [35.0,4.0]|\n",
      "|  13|Female| 58|            80000|                    15|    Executive|              0|          5|          [58.0,0.0]|\n",
      "|  14|Female| 24|            91000|                    77|       Lawyer|              1|          1|          [24.0,1.0]|\n",
      "|  15|  Male| 37|            19000|                    13|       Doctor|              0|          1|          [37.0,0.0]|\n",
      "|  16|  Male| 22|            51000|                    79|   Healthcare|              1|          2|          [22.0,1.0]|\n",
      "|  17|Female| 35|            29000|                    35|    Homemaker|              9|          5|          [35.0,9.0]|\n",
      "|  18|  Male| 20|            89000|                    66|   Healthcare|              1|          6|          [20.0,1.0]|\n",
      "|  19|  Male| 52|            20000|                    29|Entertainment|              1|          4|          [52.0,1.0]|\n",
      "|  20|Female| 35|            62000|                    98|       Artist|              0|          1|          [35.0,0.0]|\n",
      "+----+------+---+-----------------+----------------------+-------------+---------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "085b5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"Annual Income ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15068430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|Independent Features|Annual Income ($)|\n",
      "+--------------------+-----------------+\n",
      "|          [19.0,1.0]|            15000|\n",
      "|          [21.0,3.0]|            35000|\n",
      "|          [20.0,1.0]|            86000|\n",
      "|          [23.0,0.0]|            59000|\n",
      "|          [31.0,2.0]|            38000|\n",
      "|          [22.0,0.0]|            58000|\n",
      "|          [35.0,1.0]|            31000|\n",
      "|          [23.0,1.0]|            84000|\n",
      "|          [64.0,0.0]|            97000|\n",
      "|          [30.0,1.0]|            98000|\n",
      "|          [67.0,1.0]|             7000|\n",
      "|          [35.0,4.0]|            93000|\n",
      "|          [58.0,0.0]|            80000|\n",
      "|          [24.0,1.0]|            91000|\n",
      "|          [37.0,0.0]|            19000|\n",
      "|          [22.0,1.0]|            51000|\n",
      "|          [35.0,9.0]|            29000|\n",
      "|          [20.0,1.0]|            89000|\n",
      "|          [52.0,1.0]|            20000|\n",
      "|          [35.0,0.0]|            62000|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da915b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='Annual Income ($)')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ad87caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([5.8638, 1030.624])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Coefficients\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0d7c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106059.22706200839"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Intercepts\n",
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "50c9181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction\n",
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b1d61b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------------+\n",
      "|Independent Features|Annual Income ($)|        prediction|\n",
      "+--------------------+-----------------+------------------+\n",
      "|           [0.0,1.0]|            61228|107089.85101772021|\n",
      "|           [0.0,1.0]|            68761|107089.85101772021|\n",
      "|           [1.0,0.0]|            12000|106065.09090685195|\n",
      "|           [1.0,0.0]|            79800|106065.09090685195|\n",
      "|           [1.0,0.0]|           106841|106065.09090685195|\n",
      "|           [1.0,1.0]|           141307|107095.71486256378|\n",
      "|           [1.0,2.0]|           150174| 108126.3388182756|\n",
      "|           [1.0,3.0]|           138656|109156.96277398744|\n",
      "|           [1.0,8.0]|            92674|114310.08255254658|\n",
      "|           [1.0,9.0]|           100429| 115340.7065082584|\n",
      "|           [1.0,9.0]|           140648| 115340.7065082584|\n",
      "|          [1.0,12.0]|            89144|118432.57837539389|\n",
      "|           [2.0,1.0]|            52727|107101.57870740735|\n",
      "|           [2.0,4.0]|           101451|110193.45057454283|\n",
      "|           [2.0,6.0]|           111618|112254.69848596648|\n",
      "|           [2.0,8.0]|           175208|114315.94639739014|\n",
      "|           [2.0,9.0]|            56782|115346.57035310197|\n",
      "|           [3.0,1.0]|           183851|107107.44255225091|\n",
      "|           [3.0,2.0]|           117638|108138.06650796274|\n",
      "|           [3.0,8.0]|            55634|114321.81024223371|\n",
      "+--------------------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c11cc56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37249.08681700133, 1960499510.5941894)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51847adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
